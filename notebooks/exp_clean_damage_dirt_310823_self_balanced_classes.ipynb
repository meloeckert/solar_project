{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "31aced20",
   "metadata": {},
   "source": [
    "# Experiment: Model with 3 classes (clean, damaged, dirt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dff86168-1016-4ae3-8fe3-87054d08abe0",
   "metadata": {},
   "source": [
    "## Unbalaced classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "205e029f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load images\n",
    "from tensorflow.keras.preprocessing.image import array_to_img, img_to_array, load_img\n",
    "from tensorflow.keras.utils import image_dataset_from_directory\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras import layers, optimizers, callbacks\n",
    "import matplotlib.pyplot as plt \n",
    "from tensorflow.keras.losses import SparseCategoricalCrossentropy\n",
    "from PIL import Image\n",
    "import os\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10c805b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "current_path = os.getcwd()\n",
    "print(current_path)\n",
    "#test_data_dir = os.path.join(current_path,\"..\", \"raw_data/exp2-val-data-balanced/dirt\")\n",
    "\n",
    "train_data_dir = os.path.join(current_path,\"..\",\"raw_data/exp2-training-data-balanced/\")\n",
    "test_data_dir = os.path.join(current_path,\"..\",\"raw_data/exp2-val-data-balanced/\")\n",
    "\n",
    "train_data = image_dataset_from_directory(\n",
    "  train_data_dir,\n",
    "  #labels = \"inferred\",\n",
    "  label_mode = \"int\",  \n",
    "  seed=123,\n",
    "  image_size=(225, 225),\n",
    "  batch_size=batch_size,\n",
    "  #validation_split=0.2,\n",
    "  #subset='both'\n",
    ") \n",
    "val_data = image_dataset_from_directory(\n",
    "   test_data_dir,\n",
    "   #labels = \"inferred\",\n",
    "   label_mode = \"int\",\n",
    "   seed=123,\n",
    "   image_size=(225, 225),\n",
    "   batch_size=batch_size,\n",
    " )\n",
    "\n",
    "#train_data = train_ds[0]\n",
    "#val_data = train_ds[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e03f6b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes1 = train_data.class_names\n",
    "classes1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efc10899",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes2 = val_data.class_names\n",
    "classes2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a699092d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "current_path = os.getcwd()\n",
    "print(current_path)\n",
    "test_data_dir = os.path.join(current_path,\"..\", \"raw_data/exp2-val-data-balanced/dirt\")\n",
    "print(test_data_dir)\n",
    "# Specify the directory path you want to list files in\n",
    "directory = test_data_dir\n",
    "\n",
    "# List all files in the directory\n",
    "file_list = [f for f in os.listdir(directory) if os.path.isfile(os.path.join(directory, f))]\n",
    "\n",
    "# Print the list of files\n",
    "for file in file_list:\n",
    "    print(file)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64e25720",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ced0be1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We'll use a model with the same convolutional layers, but we'll add Augmentation layers before that\n",
    "\n",
    "model_multi = Sequential()\n",
    "\n",
    "model_multi.add(layers.Rescaling(1./255, input_shape = (225, 225, 3)))\n",
    "\n",
    "# Data Augmentation Layers\n",
    "\n",
    "model_multi.add(layers.RandomFlip(\"horizontal\"))\n",
    "model_multi.add(layers.RandomZoom(0.1))\n",
    "model_multi.add(layers.RandomTranslation(0.2, 0.2))\n",
    "model_multi.add(layers.RandomRotation(0.1))\n",
    "\n",
    "\n",
    "# Convolutional Layers\n",
    "\n",
    "model_multi.add(layers.Conv2D(filters = 32, kernel_size = (3,3), activation=\"relu\", padding = \"same\"))\n",
    "model_multi.add(layers.MaxPooling2D(pool_size=(2, 2), padding = \"same\") )\n",
    "\n",
    "\n",
    "model_multi.add(layers.Conv2D(filters = 32, kernel_size = (3,3), input_shape = (225, 225, 3), activation=\"relu\", padding = \"same\"))\n",
    "model_multi.add(layers.MaxPooling2D(pool_size=(2, 2), padding = \"same\") )\n",
    "\n",
    "\n",
    "model_multi.add(layers.Conv2D(filters = 64, kernel_size = (3,3), input_shape = (225, 225, 3), activation=\"relu\", padding = \"same\"))\n",
    "model_multi.add(layers.MaxPooling2D(pool_size=(2, 2), padding = \"same\") )\n",
    "\n",
    "model_multi.add(layers.Conv2D(filters = 128, kernel_size = (3,3), input_shape = (225, 225, 3), activation=\"relu\", padding = \"same\"))\n",
    "model_multi.add(layers.MaxPooling2D(pool_size=(2, 2), padding = \"same\") )\n",
    "\n",
    "model_multi.add(layers.Flatten())\n",
    "\n",
    "model_multi.add(layers.Dense(64, activation=\"relu\"))\n",
    "\n",
    "model_multi.add(layers.Dropout(0.5))\n",
    "\n",
    "model_multi.add(layers.Dense(3, activation=\"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56f3faa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_multi.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5bfe794",
   "metadata": {},
   "outputs": [],
   "source": [
    "adam = optimizers.Adam(learning_rate = 0.001)\n",
    "\n",
    "model_multi.compile(loss= SparseCategoricalCrossentropy(),\n",
    "              optimizer= adam,\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dd6dc7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL = \"model_multiclass_clean_damage_dirt_230904_self_balanced\"\n",
    "\n",
    "modelCheckpoint = callbacks.ModelCheckpoint(\"{}.h5\".format(MODEL), monitor=\"val_loss\", verbose=0, save_best_only=True)\n",
    "\n",
    "LRreducer = callbacks.ReduceLROnPlateau(monitor=\"val_loss\", factor = 0.1, patience=3, verbose=1, min_lr=0)\n",
    "\n",
    "EarlyStopper = callbacks.EarlyStopping(monitor='val_loss', patience=10, verbose=0, restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "933cf1f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#new weights - remove snow images, and macro pic of bird\n",
    "clean = 133\n",
    "damage = 133\n",
    "dirt = 133\n",
    "total = clean + damage + dirt\n",
    "print(f'total: {total}')\n",
    "clean_weight =  (clean/total)**-1\n",
    "damage_weight = (damage/total)**-1\n",
    "dirt_weight = (dirt/total)**-1\n",
    "print(f\"clean weight: {clean_weight}\")\n",
    "print(f\"damage weight: {damage_weight}\")\n",
    "print(f\"dirt weight: {dirt_weight}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "274fda52",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "#'clean', 'damage', 'dirt'\n",
    "history_multi = model_multi.fit(\n",
    "        train_data,\n",
    "        epochs=30,\n",
    "        validation_data=val_data,\n",
    "        callbacks = [modelCheckpoint, LRreducer, EarlyStopper],\n",
    "        class_weight = {\n",
    "            0: 3.0,\n",
    "            1: 3.0,\n",
    "            2: 3.0\n",
    "        }\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8800b62",
   "metadata": {},
   "outputs": [],
   "source": [
    "#improvement = (0.51 - (1/3))/(1/3)\n",
    "#improvement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b5d2757",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_history(history):\n",
    "    fig, ax = plt.subplots(1, 2, figsize=(15,5))\n",
    "    ax[0].set_title('loss')\n",
    "    ax[0].plot(history.epoch, history.history[\"loss\"], label=\"Train loss\")\n",
    "    ax[0].plot(history.epoch, history.history[\"val_loss\"], label=\"Validation loss\")\n",
    "    ax[1].set_title('accuracy')\n",
    "    ax[1].plot(history.epoch, history.history[\"accuracy\"], label=\"Train acc\")\n",
    "    ax[1].plot(history.epoch, history.history[\"val_accuracy\"], label=\"Validation acc\")\n",
    "    ax[0].legend()\n",
    "    ax[1].legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df683832",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_history(history_multi)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24ec1d88",
   "metadata": {},
   "source": [
    "### Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6da0cb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_index_of_max_element(input_list):\n",
    "    max_value = max(input_list)\n",
    "    max_index = input_list.index(max_value)\n",
    "    return max_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc5a8b84",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predictImage_multiclass(url, model):\n",
    "\n",
    "  # Takes an image and a model\n",
    "\n",
    "  img = url\n",
    "  img = img_to_array(img)\n",
    "  img = img.reshape((-1, 225, 225, 3))\n",
    "  res = model.predict(img)\n",
    "  print(f\"Probabilities: \")\n",
    "  names_of_classes = class_names\n",
    "  print(f\"{names_of_classes}\")\n",
    "  print(f\"{res[0]}\")\n",
    "  print(f\"Result: {names_of_classes[find_index_of_max_element(res[0].tolist())]}\")  \n",
    "  return res "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d59e4e00",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20d7dc8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# img_clean_1 = load_img(f\"raw_data/training-data/clean/Cleaan (4).jpeg\", target_size=(225, 225))\n",
    "# predictImage_multiclass(img_clean_1,model_multi)\n",
    "# plt.imshow(img_clean_1);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fec8e8f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# img_clean_1 = load_img(f\"raw_data/training-data/clean/Cleaan (12).jpeg\", target_size=(225, 225))\n",
    "# predictImage_multiclass(img_clean_1,model_multi)\n",
    "# plt.imshow(img_clean_1);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a3d357a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# img_clean_1 = load_img(f\"raw_data/training-data/clean/Cleaan (21).jpeg\", target_size=(225, 225))\n",
    "# predictImage_multiclass(img_clean_1,model_multi)\n",
    "# plt.imshow(img_clean_1);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2039e84b",
   "metadata": {},
   "source": [
    "### Snow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c33b8635",
   "metadata": {},
   "outputs": [],
   "source": [
    "# img_snow = load_img(f\"raw_data/training-data/solar/Solar (3).jpeg\", target_size=(225, 225))\n",
    "# predictImage_multiclass(img_snow,model_multi)\n",
    "# plt.imshow(img_snow);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9a27615",
   "metadata": {},
   "outputs": [],
   "source": [
    "# img_snow = load_img(f\"raw_data/training-data/solar/Solar (12).jpeg\", target_size=(225, 225))\n",
    "# predictImage_multiclass(img_snow,model_multi)\n",
    "# plt.imshow(img_snow);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1ef96fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# img_snow = load_img(f\"raw_data/training-data/solar/Solar (33).jpeg\", target_size=(225, 225))\n",
    "# predictImage_multiclass(img_snow,model_multi)\n",
    "# plt.imshow(img_snow);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb6b8e97",
   "metadata": {},
   "source": [
    "### Damage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07944347",
   "metadata": {},
   "outputs": [],
   "source": [
    "# img_electrical = load_img(f\"raw_data/training-data/electrical/Electrical (29).jpeg\", target_size=(225, 225))\n",
    "# predictImage_multiclass(img_electrical,model_multi)\n",
    "# plt.imshow(img_electrical);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "995401cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# img_physical = load_img(f\"raw_data/training-data/physical_damaged/Physical-damaged (37).jpeg\", target_size=(225, 225))\n",
    "# predictImage_multiclass(img_physical,model_multi)\n",
    "# plt.imshow(img_physical);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d7aec41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# img_physical = load_img(f\"raw_data/training-data-exp/damage/Electrical (23).jpeg\", target_size=(225, 225))\n",
    "# predictImage_multiclass(img_physical,model_multi)\n",
    "# plt.imshow(img_physical);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b6e2603",
   "metadata": {},
   "source": [
    "### Bird or dust\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22b286d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "##pics bird 37,55,59,  --> macro pic on brid drop --> predicting wrong class\n",
    "# pic 65\n",
    "# img_physical = load_img(f\"raw_data/training-data/bird/Bird (65).jpeg\", target_size=(225, 225))\n",
    "# predictImage_multiclass(img_physical,model_multi)\n",
    "# plt.imshow(img_physical);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2ebd73b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# img_physical = load_img(f\"raw_data/training-data/bird/Bird (5).jpeg\", target_size=(225, 225))\n",
    "# predictImage_multiclass(img_physical,model_multi)\n",
    "# plt.imshow(img_physical);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30800da0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#img_physical = load_img(f\"raw_data/training-data-exp/dirt/Bird (47).jpeg\", target_size=(225, 225))\n",
    "#predictImage_multiclass(img_physical,model_multi)\n",
    "#plt.imshow(img_physical);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46053e10",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predictImage_multiclass(url, model):\n",
    "\n",
    "  # Takes an image and a model\n",
    "\n",
    "  img = url\n",
    "  img = img_to_array(img)\n",
    "  img = img.reshape((-1, 225, 225, 3))\n",
    "  res = model.predict(img)\n",
    "  print(f\"Probabilities: \")\n",
    "  names_of_classes = ['clean','damaged','dirty']\n",
    "  print(f\"{names_of_classes}\")\n",
    "  print(f\"{res[0]}\")\n",
    "  print(f\"Result: {names_of_classes[find_index_of_max_element(res[0].tolist())]}\")  \n",
    "  return res "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81984441",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow.math import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "\n",
    "predictions = np.array([])\n",
    "print(predictions.shape)\n",
    "labels =  np.array([])\n",
    "for x, y in val_data:\n",
    "    \n",
    "  pred = model_multi.predict(x)\n",
    "  pred = np.argmax(pred, axis=-1)\n",
    "  print(f\"pred {pred.shape}\")\n",
    "  predictions = np.concatenate([predictions, pred ])\n",
    "  label =  np.argmax(y.numpy(), axis=-1)\n",
    "  print(f\"label shape {label.shape}\")\n",
    "  labels = np.concatenate([labels, y])  #np.argmax(y.numpy()\n",
    "\n",
    "report = classification_report(labels, predictions, target_names=classes1)\n",
    "\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bece1e0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix(labels=labels, predictions=predictions).numpy()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27ae9b69",
   "metadata": {},
   "source": [
    "## Test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8933bde5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch_size = 8\n",
    "# test_data_dir = \"raw_data/exp-test-data/\"\n",
    "\n",
    "# test_data = image_dataset_from_directory(\n",
    "#   test_data_dir,\n",
    "#   #labels = \"inferred\",\n",
    "#   label_mode = \"int\",  \n",
    "#   seed=123,\n",
    "#   image_size=(225, 225),\n",
    "#   batch_size=batch_size,\n",
    "# ) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eba35b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predictions = np.array([])\n",
    "# print(predictions.shape)\n",
    "# labels =  np.array([])\n",
    "# for x, y in test_data:\n",
    "    \n",
    "#   pred = model_multi.predict(x)\n",
    "#   pred = np.argmax(pred, axis=-1)\n",
    "#   print(f\"pred {pred.shape}\")\n",
    "#   predictions = np.concatenate([predictions, pred ])\n",
    "#   label =  np.argmax(y.numpy(), axis=-1)\n",
    "#   print(f\"label shape {label.shape}\")\n",
    "#   labels = np.concatenate([labels, y])  #np.argmax(y.numpy()\n",
    "\n",
    "# report = classification_report(labels, predictions, target_names=classes1)\n",
    "\n",
    "# print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34175573",
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix(labels=labels, predictions=predictions).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ac0348f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow.math import confusion_matrix\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f0ee6b3-375c-4584-9085-3579cafcae36",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = np.array([])\n",
    "probabilities_clean = np.array([])\n",
    "labels =  np.array([])\n",
    "\n",
    "for x, y in val_data:\n",
    "    \n",
    "  prediction_array = model_multi.predict(x)\n",
    "  probability_clean = prediction_array\n",
    "  #probability_clean = np.squeeze(probability_clean)  \n",
    "  #print(f'prob clean: {probability_clean}')  \n",
    "  probabilities_clean = np.append(probabilities_clean, probability_clean)\n",
    "    \n",
    "  pred = np.argmax(prediction_array, axis=-1)\n",
    "\n",
    "  predictions = np.concatenate([predictions, pred ])\n",
    "\n",
    "  labels = np.concatenate([labels, y])  #np.argmax(y.numpy()\n",
    "\n",
    "report = classification_report(labels, predictions, target_names=classes1)\n",
    "\n",
    "print(report)\n",
    "reshaped_array = probabilities_clean.reshape(-1, 3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b505bb2c-8b91-4e4a-8fa2-dc08f1a1ac58",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_curve\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a0e0a9c-639d-4010-8af1-250f3932cbb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "precision, recall, threshold = precision_recall_curve(labels, probabilities_clean)\n",
    "scores = pd.DataFrame({'threshold':threshold,\n",
    "                       'precision': precision[:-1],\n",
    "                       'recall':recall[:-1]}) # Store in a dataframe\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65812742-f1b7-47e6-9b6c-8ae68d192cdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(scores['recall'],scores['precision'])\n",
    "plt.ylabel('precision')\n",
    "plt.xlabel('recall')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1998eb9a-11d2-471e-be95-0a28e7ef30f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_threshold = scores[scores['precision'] >= 0.4].threshold.min()\n",
    "new_threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb80d339-abcf-4f48-ae8d-a2fe58cee852",
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_predict(X, custom_threshold, model):\n",
    "    probability = model.predict(X) # Get likelihood of each sample being classified as 0 or 1\n",
    "    proba_clean = 1- probability[:,-1]\n",
    "    #print(modified_array)\n",
    "    #more_5y_probs = probability[:, 1] # Only keep expensive likelihoods (1) \n",
    "    return (proba_clean > custom_threshold).astype(int) # Boolean outcome converted to 0 or 1\n",
    "\n",
    "pred_thres = np.array([])\n",
    "\n",
    "for x, y in val_data:    \n",
    "    updated_preds = custom_predict(X=x, custom_threshold=0.6, model=model_multi) # Update prediction\n",
    "    updated_preds = np.squeeze(updated_preds)\n",
    "    pred_thres = np.concatenate([pred_thres, updated_preds])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7fc84d1-de39-431a-bcf5-47a076a53120",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09d99550-f88d-4402-abf9-ecb4550e880f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_thres.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe3febd5-bc1c-4ff5-90af-b32aa09d8934",
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix(labels=labels, predictions=pred_thres).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "813dd69f-0232-4b5a-9e2a-a676b3db1a25",
   "metadata": {},
   "outputs": [],
   "source": [
    "report = classification_report(labels, pred_thres, target_names=class_names)\n",
    "\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da27f41d-1284-433e-a3e0-d33f7bec8236",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ba89275-1782-44be-b07d-ac5377862e8d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1e745b1-8188-4bdb-8bc8-e67aad978b69",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a150a15-ef9d-4cb8-97bf-915f4a152557",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "import numpy as np\n",
    "print(f'labels shape: {labels.shape}')\n",
    "# Assuming 'probs' is the predicted probabilities for each class\n",
    "# 'thresholds' is a list of chosen thresholds for each class\n",
    "thresholds = [0.8, 0.8, 0.8]\n",
    "\n",
    "probs = reshaped_array\n",
    "print(len(reshaped_array[:,0]))\n",
    "# Apply threshold adjustment\n",
    "adjusted_predictions = []\n",
    "labels_matrix = []\n",
    "for j, label in zip(range(len(probs[:,0])),labels):\n",
    "    prob_element = probs[j,:]\n",
    "    #print(f'prob_element: {prob_element}')\n",
    "    #for i in range(len(prob_element)):\n",
    "    adjustment = [1 if p >= thresholds[c] else 0 for c, p in enumerate(prob_element)]\n",
    "    labels_mat = [1 if label==c else 0 for c, l in enumerate(range(len(prob_element)))]\n",
    "    #print(f'labels_mat: {labels_mat}, label: {label}')\n",
    "    #print(f\"adjustment: {adjustment}\")\n",
    "    #adjustment = np.argmax(adjustment, axis=-1)\n",
    "    adjusted_predictions.append(adjustment)\n",
    "    labels_matrix.append(labels_mat)\n",
    "# Convert to NumPy array\n",
    "adjusted_predictions = np.array(adjusted_predictions)\n",
    "labels_matrix = np.array(labels_matrix)\n",
    "print(f'adjust pred: {adjusted_predictions.shape}')\n",
    "\n",
    "# Assuming 'labels' is the ground truth labels\n",
    "class_names = ['class_1', 'class_2', 'class_3']\n",
    "\n",
    "#labels = \n",
    "print(f'labels_matrix shape: {labels_matrix.shape}')\n",
    "# Generate classification report for each class\n",
    "for c in range(len(class_names)): #range(len(labels)): #\n",
    "    print(f\"Metrics for {class_names[c]}:\")\n",
    "    class_labels = labels_matrix[:, c]  # Extract labels for the current class   # c \n",
    "    class_predictions = adjusted_predictions[:, c]  # Extract adjusted predictions for the current class\n",
    "    report = classification_report(class_labels, class_predictions)\n",
    "    print(report)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "342c238f-9072-4907-ad9f-86f649f49b20",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_array = np.array([0.3, 0.4,0.3])\n",
    "pred = np.argmax(prediction_array, axis=-1)\n",
    "pred"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
